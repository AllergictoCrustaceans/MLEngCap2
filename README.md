
# Bankmarketing 

The purpose of this capstone is to deploy the best model generated by autoML, and make predictions with said model from an HTTP endpoint via a published and consumed pipeline.

## Architectural Diagram


## Key Steps
### 1.) Authentication
![Authentication Setup with Azure SDK CLI](mleng_cap2_auth_setup.jpg) 
Before we do any AutoML magic, we should authenticate the user that is using the AzureML workspace and resource group to train and deploy a model. In this capstone project, I authenticated an Azure Portal user (me) through creating a "Service Principal" role with controlled permissions to access specific resources. In my case, the workspace `cap-tryout` and resource group `mleng` is shared to me, with my specific client id (--- whited out ---). 

--------------------------------------------------------

### 2.) AutoML via ML Studio
![Uploaded bankmarketing.csv dataset via Azure Portal](mleng_cap2_registered_dataset.png)
After the user is authenticated, the next step is to upload a dataset for the AutoML experiement to train on. For this capstone project, I downloaded the bankmarketing.csv locally, and uploaded it via the Azure Portal as a tabular dataset, with `y` as our label.

--------------------------------------------------------

![AutoML Experiment Completion Status](mleng_cap2_automl_completion.png)
Next is to create a new autoML experiment. After we initiated an autoML experiment with this dataset, we wait for it to finish training. The picture above is a reference of what the AutoML experiment status looks like once it is done training.

---------------------------------------------------------

![Best Model Yielded by AutoML Run](mleng_cap2_best_model.png)
Along with its completion, the AutoML experiment we just ran usually outputs the best model that yields the best accuracy. In our case, we have Voting Ensemble as our best model, yielding an accuracy of 94.697%.

---------------------------------------------------------

### 3.) Deploy the Best Model
![]()
Select the best model, and deploy it. In the screenshot above, I make sure that our compute type is Azure Container Instance, authentication is enabled.

---------------------------------------------------------

### 4.) Enable Logging 

![](mleng_cap2_log_output.png)

---------------------------------------------------------

![](mleng_cap2_app_insights_enabled.png)
We have to enable app insights to `True ` in order to monitor metrics of the model as its deployed to a REST endpoint.

---------------------------------------------------------

### 5.) Swagger Documentation
![](mleng_cap2_swagger_localhost.png)
Ideally, if we were to develop a web service for the model we just deployed, it's good practice to provide API documentation on how to use our model. Swagger is a quick way to get our endpoints documented, along with the request parameters needed in order to yield appropriate responses from the server. 

---------------------------------------------------------

### 6.) Consume Model Endpoint
![](mleng_cap2_endpoint_json_output.png)
Just to verify that we can make predictions from our deployed endpoint API endpoint `/score`, we run `endpoint.py` which holds a function to make a request -- with params (url, api_key, headers) -- to our model, and the results from the model comes back as a repsonse (yes or no).

---------------------------------------------------------

### 7.) Create, Publish and Consume a Pipeline
![Pipeline Creation](mleng_cap2_pipeline_created.png)
In this project, we created a pipeline to ensure a smoother model deployment process. The pipeline can be created via Azure Portal GUI, or by using the Azure SDK `from azureml.pipeline.core import Pipeline`, and defining the parameters of what our Pipeline should have (description, workspace, steps). After we've defined our Pipeline settings, we then run it with `pipeline_run = experiment.submit(pipeline)`, and use the `azureml.widgets import RunDetails` package to help us visualize the process of the pipeline being executed. The screenshot above indicates that two pipelines have been created, and are currently running. 

----------------------------------------------------------

![Published Pipeline to an HTTP Endpoint](mleng_cap2_pipeline_endpoint.png)
Once the pipeline has finished, we publish the pipeline to ensure that the pipeline is publicly accessible. In the picture above, we have one pipeline published, with a public HTTP endpoint available for users to make a call with. 

----------------------------------------------------------

![Bankmarketing.csv dataset used for published Pipeline](mleng_cap2_dataset_automl_module.png)
This image also verifies that the published pipeline uses the dataset that was used for its model training to make predictions from the HTTP endpoint.

----------------------------------------------------------

![Published Pipeline Overview](mleng_cap2_published_pipeline_overview.png)
The image above shows the overview specs of what the published pipeline is configured with. 

----------------------------------------------------------

![Pipeline Creation Widget](mleng_cap2_rundetails_widget.png)
The image above shows an azure widget, helping us visualize the duration/process of running the pipeline.

----------------------------------------------------------

![Pipeline Scheduled Run](mleng_cap2_scheduled_run.png)
The image above shows us the pipelines are on a scheduled run once it has been created.

----------------------------------------------------------

### 8.) Demo It! 
This is the screen recording part, which is linked below!

## Screen Recording

----------------------------------------------------------

## Standout Suggestions
Nothing outstanding done in this repo. However -- it'd be neat to build a web app with this!
An update of this repo may happen in the near future :D